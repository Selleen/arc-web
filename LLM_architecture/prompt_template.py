llama_template = (
    "<|begin_of_text|>"
    "<|start_header_id|>system<|end_header_id|>\n\n"
    "{system_prompt}<|eot_id|>\n"
    "<|start_header_id|>user<|end_header_id|>\n\n"
    "{user_prompt}<|eot_id|>\n"
    "<|start_header_id|>assistant<|end_header_id|>\n\n"
    "{{\"material_and_processes\": "
)

review_classification_system_prompt = "You are an expert evaluator of software-based artworks."

review_classification_template = """ 
Given the code below, classify it according to the following framework for generative art analysis.

---

### Framework

**Material and Processes:**
- processed_audio: The code uses pre-existing audio files (e.g., mp3, wav, midi) as input.
- processed_image: The code loads or manipulates already existing images or videos.
- processed_text: The code takes already written texts (e.g., documents, strings) and transforms them.
- synthesized_sound: The code generates new sound algorithmically (e.g., oscillators, generators).
- synthesized_image: The code generates new graphics (e.g., lines, shapes, fractals, shaders).
- synthesized_text: The text is generated by the algorithm (e.g., Markov, GPT, rules).
- randomness: The code uses random functions to influence generation or processing.
- interactions: Internal elements of the system affect each other (e.g., audio -> visual).

**Environmental interaction:**
- human_interaction: The artwork is influenced by human actions(user input) (e.g., mouse clicks, midi controller, microphone, keyboard, camera, motion sensor, touch, lidar, among others).
- computer_interaction: The artwork receives input from external computational sources (APIs, data file, automatic sensors, data stream, remote data, among others).
- none: No external input of any kind.

**Sensory outcomes:**
- visual: produces visual output.
- auditory: produces auditory output.
- physical: produces real physical effects.
- static: the work may animate or react to input, but its overall structure and content do NOT meaningfully progress over time. The scene can loop forever or keep responding to the user, but if you compare the work after a long time with an earlier moment, you are essentially seeing the same kind of state (no accumulation of new elements, no irreversible stages, no narrative timeline). Simple continuous motion (e.g. rotation with frameCount, oscillations, or mouse-based lighting) still counts as "static" for this task.
- time_based: the work clearly unfolds or progresses over time, even if the user does nothing. For example, it accumulates new elements in arrays or lists, reveals new text or images step by step, follows an audio or video timeline, moves through distinct phases, or ends in a state that is systematically different from how it started (e.g. more and more objects appear until a final message is shown). Use "time_based" when the code encodes a temporal narrative, growth, or accumulation.

(Refer to these categories using the **EXACT LABELS** above.)

Important notes:
- In Sensory outcomes, it is mandatory to have **at least one** of "static" or "time_based".

---

### Requirements

1. Read the code.
2. Choose all values that apply to its generative or artistic behavior.
3. Return a structured JSON as follows:

```json
{{
  "material_and_processes": [...],
  "interaction": [...],
  "outcome": [...],
  "explanation": [
    "Concise reasoning referencing variables, libraries, or functions in the code."
  ],
  "reuse_algorithm": "Brief note on algorithm reuse or novelty."
}}

### Code to analyze
(extension = {extension}, file_name = {file_name})
Content:

{artwork}
"""
